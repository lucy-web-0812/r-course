---
title: "R Intro Reference"
author: "Stuart & Will"
date: "WACL"
output: 
  bookdown::html_document2:
    theme: flatly
    toc: TRUE
    toc_float: TRUE
    toc_depth: 2
---

```{css, echo = FALSE}
h1, .h1, h2, .h2, h3, .h3 {
    margin-top: 84px;
}
```


```{r include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = FALSE)
```

# Purpose {-}

This document is not for learners to see. This is to act as a reference while teaching each section.

No code in this document is evaluated.

# Morning session: Reading data & stats

## Reading and Interrogating Data

### Walkthrough

-   Setting up a project

-   RStudio setup: environemnt + base pipe

-   Use of `read.csv()`

-   Printing to the console.

```{r}
my1_no = read.csv("data/taught/part_1/MY1_no_2018.csv")

my1_no
```

Viewing data.

-  What is dplyr?

-  Glimpse, View (analogous to Excel).

- Tibble (improved printing)

```{r}
library(dplyr)

glimpse(my1_no)
View(my1_no)

tibble(my1_no)

my1_no = tibble(my1_no)

```

Use of the pipe.

```{r}
# Functionally the same! Why use pipe?
tibble(my1_no)
my1_no |> tibble()

# Without pipe
my1_no = read.csv("data/taught/part_1/MY1_no_2018.csv") 
my1_no = tibble(my1_no)

# With pipe we don't have to create intermediate variables
my1_no = read.csv("data/taught/part_1/MY1_no_2018.csv") |> 
  tibble()

```

Talk about data types.

-  Indexing a column (refresh from before.)

-  `no` is fine.

-  `date` is not.

-  Use of `lubridate` - what is it? (part of tidyverse - make link)

```{r}
class(my1_no$no)

class(my1_no$date)

library(lubridate)

my1_no$date = ymd_hms(my1_no$date)

my1_no

class(my1_no$date)
```

Initial merge.

-  How to merge? From `dplyr`

-  Use of "by" argument - is it needed? when? When not?

-  Base R plot - not pretty, but good for double checking

```{r}
my1_no2 = read.csv("data/taught/part_1/MY1_no2_2018.csv")
my1_no2$date = ymd_hms(my1_no2$date)

my1 = left_join(my1_no, my1_no2, by = "date")

plot(my1_$no, my1_$no2)
```

Many merge.

-  Compare many functions vs. pipeline.

```{r}
my1 = left_join(my1_no, my1_o3, by = "date") # tedious!

my1 = my1_no |> 
  left_join(my1_no2, by = "date") |> 
  left_join(my1_o3, by = "date") |> 
  left_join(my1_met, by = "date")
```

### Script Update

```{r}
library(dplyr)
library(lubridate)

my1_no = read.csv("data/taught/part_1/MY1_no_2018.csv") |> 
  tibble() |> 
  mutate(date = ymd_hms(date)) 

my1_no2 = read.csv("data/taught/part_1/MY1_no2_2018.csv") |> 
  tibble() |> 
  mutate(date = ymd_hms(date))

my1_o3 = read.csv("data/taught/part_1/MY1_o3_2018.csv") |> 
  tibble() |> 
  mutate(date = ymd_hms(date))

my1_met = read.csv("data/taught/part_1/MY1_met_2018.csv") |> 
  tibble() |> 
  mutate(date = ymd_hms(date)) |> 
  select(-X)

my1 = my1_no |> 
  left_join(my1_no2, by = "date") |> 
  left_join(my1_o3, by = "date") |> 
  left_join(my1_met, by = "date") |>
  mutate(nox = no+no2)

```

### Exercise!

  - Reading in data exercise

## Basic Statistical Analysis

### Walkthrough

Use of `mean`.

-  Use mean on column (refresh from before).

-  Talk about `na.rm` - it's everywhere.

-  Warn about being sensible - averaging wind direction isn't obvious, R can't read minds.

```{r}
mean(my1$no)

mean(my1$no, na.rm = T)

mean(my1$wind_direction, na.rm = T) # averaging wind direction warning

```

Other statistical tools.

-  Reinforce what these return (range returns a vector, analogue to max and min)

```{r}
median(my1$o3, na.rm = T)

sd(my1$wind_speed, na.rm = T)

range(my1$nox, na.rm = T)
```

Exploratory visualisations.

```{r}
hist(my1$no)
```

Histogram nice but arbitrary, density functions are also useful. Build up:

-  First thing errors - what does that say? How to debug.

-  Use na.omit to get rid of NA values.

-  Use generic "plot" function to plot.

```{r}
density(my1$no)

na.omit(my1$no) |> 
  density()

na.omit(my1$no) |> 
  density() |> 
  plot()
```

Correlation - classic scatter plot.

```{r}
plot(my1$no,my1$nox)
```

Basic modelling to get an R Squared. 

- Note that Excel hides a lot of this stuff.

- Check the lm function help pane.

- Fit model.

- Summarise the model (more descriptive).

- Store model object - new type of object (can predict with this etc.)

- Pull out of the coefficents.

```{r}
?lm

lm(formula = nox~no, data = my1)

linearModel = lm(my1$nox~my1$no)

coef(linearModel)

coef(linearModel)[1]

coef(linearModel)[2]
```

Plot our line of best fit.

-  Plot the data.

-  View help pane.

-  Layer on the abline (to show the model is doing what we think it is!)

```{r}
plot(my1$no,my1$nox)

?abline

abline(a = coef(linearModel)[1], b = coef(linearModel)[2], col = "red")
```

### Script Update

```{r}
library(dplyr)
library(lubridate)

my1_no = read.csv("data/taught/part_1/MY1_no_2018.csv") |> 
  tibble() |> 
  mutate(date = ymd_hms(date)) 

my1_no2 = read.csv("data/taught/part_1/MY1_no2_2018.csv") |> 
  tibble() |> 
  mutate(date = ymd_hms(date))

my1_o3 = read.csv("data/taught/part_1/MY1_o3_2018.csv") |> 
  tibble() |> 
  mutate(date = ymd_hms(date))

my1_met = read.csv("data/taught/part_1/MY1_met_2018.csv") |> 
  tibble() |> 
  mutate(date = ymd_hms(date)) |> 
  select(-X)

my1 = my1_no |> 
  left_join(my1_no2, by = "date") |> 
  left_join(my1_o3, by = "date") |> 
  left_join(my1_met, by = "date") |>
  mutate(nox = no+no2)

# plot nox~no linear model
linearModel = lm(my1$nox~my1$no)

plot(my1$no,my1$nox)
abline(a = coef(linearModel)[1], b = coef(linearModel)[2], col = "red")
```

### Exercise!

  - Statistics exercise

## Using `openair` for Air Quality Data

### Walkthrough

This is a pretty open section on what openair can do.

**Afterwords mention Vignettes?**

```{r}
library(openair)

# the wind direction averaging point could be linked here, but it might be a bit subtle? could circle back later
summaryPlot(my1)

timePlot(my1, pollutant = "no")

timePlot(my1, pollutant = c("no","no2")) # making the assumption that c() has been taught already

timePlot(my1, pollutant = c("no","no2"), y.relation = "free")

timePlot(my1, pollutant = c("no","no2"), y.relation = "free", avg.time = "1 day")


my1_daily = timeAverage(my1,"1 day")

# time to bring up renaming ws and wd

my1_daily$wind_direction |> 
  hist(breaks = 100)

my1 = my1 |> 
  rename(ws = wind_speed, 
         wd = wind_direction)

my1_daily2 = timeAverage(my1, "1 day")

my1_daily2$wd |> 
  hist(breaks = 100,
       add = T,
       col = "red")

timeVariation(my1, pollutant = c("no","no2","o3"))

timeVariation(my1, pollutant = c("no","no2","o3"), type = "season")

my1_tv = timeVariation(my1, pollutant = c("no","no2","o3"))

my1_tv$data$hour # make them aware of this? its long data though so a day 2 thing to do in detail?

windRose(my1) # ws and wd already formatted :)

windRose(my1,paddle = F)

polarPlot(my1, pol = "no") # go to google maps for a quick chat about what it means

corPlot(my1) #?

```

### Script Update

```{r}
library(dplyr)
library(lubridate)
library(openair)

my1_no = read.csv("data/taught/part_1/MY1_no_2018.csv") |> 
  tibble() |> 
  mutate(date = ymd_hms(date)) 


my1_no2 = read.csv("data/taught/part_1/MY1_no2_2018.csv") |> 
  tibble() |> 
  mutate(date = ymd_hms(date))

my1_o3 = read.csv("data/taught/part_1/MY1_o3_2018.csv") |> 
  tibble() |> 
  mutate(date = ymd_hms(date))

my1_met = read.csv("data/taught/part_1/MY1_met_2018.csv") |> 
  tibble() |> 
  mutate(date = ymd_hms(date)) |> 
  select(-X)

my1 = my1_no |> 
  left_join(my1_no2, by = "date") |> 
  left_join(my1_o3, by = "date") |> 
  left_join(my1_met, by = "date") |>
  mutate(nox = no+no2) |> 
  rename(ws = wind_speed,
         wd = wind_direction)

# plot nox~no linear model
linearModel = lm(my1$nox~my1$no)

plot(my1$no,my1$nox)
abline(a = coef(linearModel)[1], b = coef(linearModel)[2], col = "red")

# plot daily average no and no2

timePlot(my1, pollutant = c("no","no2"), y.relation = "free", avg.time = "1 day")

# plot diurnals

timeVariation(my1, pollutant = c("no","no2","o3"))

# plot polar

polarPlot(my1, pol = "no")
```

### Exercise!

  - openair exercise

# Afternoon: Flow control and tidy data

## Reading trickier data

-  Brief recap previous day (reading data).

-  List files (why is this useful?)

-  Read everything in manually - making improvements but not perfect right now.

```{r}
library(dplyr)
library(lubridate)
library(stringr)

files = list.files("data/taught/part_2")

# instead of writing the path each time, lets be lazy!
files = list.files("data/taught/part_2", full.names = T)

cll2 = read.csv(files[1]) |> 
  tibble()

cll2 = read.csv(files[1]) |> 
  tibble() |> 
  select(-X) |> 
  mutate(date = ymd_hms(date))

hors = read.csv(files[2]) |> 
  tibble() |> 
  select(-X) |> 
  mutate(date = ymd_hms(date))

kc1 = read.csv(files[3]) |> 
  tibble() |> 
  select(-X) |> 
  mutate(date = ymd_hms(date))

my1 = read.csv(files[5]) |> 
  tibble() |> 
  select(-X) |> 
  mutate(date = ymd_hms(date))

# This errors!
lon6 = read.csv(files[4]) |> 
  tibble() |> 
  select(-X) |> 
  mutate(date = ymd_hms(date))

```

- Discuss Unix time, if you ever come across a long integer that starts like this it's likely in Unix time

```{r}
lon6 = read.csv(files[4]) |> 
  tibble()
lon6
```

- Can parse using `as_datetime` rather than `ymd_hms`.

```{r}
lon6 = read.csv(files[4]) |> 
  tibble() |> 
  select(-X) |> 
  mutate(date = as_datetime(date))
```

- Can combine sites using `left_join` as saw yesterday but produces by default ugly column names

```{r}
cll2 |>
  left_join(kc1, by='date')
```

- Can fix with the `suffix` argument, but already with just 2 sites have 7 columns, will be hard to work with when add more!
- Will come back to this at the end of the exercise to highlight a more efficient way of structuring our data
- TODO Is there a killer motivating reason to use tidy data that will click before they've gotten onto vectorisation / plotting?

```{r}
cll2 |>
  left_join(kc1, by='date', suffix=c("_cll2", "_kc1"))
```

- "Tidy data" prefers to have 1 row per observation and use column values to explicitly reference sites
- Makes it easier for plotting and certain types of analysis

```{r}
rbind(
  cll2 |> mutate(site = 'cll2'),
  kc1 |> mutate(site = 'kc1')
)
```


```{r}
cll2 = read.csv(files[1]) |> 
  tibble() |> 
  select(-X) |> 
  mutate(date = ymd_hms(date),
         site = "cll2")

hors = read.csv(files[2]) |> 
  tibble() |> 
  select(-X) |> 
  mutate(date = ymd_hms(date),
         site = "hors")

kc1 = read.csv(files[3]) |> 
  tibble() |> 
  select(-X) |> 
  mutate(date = ymd_hms(date),
         site = "kc1")

lon6 = read.csv(files[4]) |> 
  tibble() |> 
  select(-X) |> 
  mutate(date = as_datetime(date),
         site = "lon6")

my1 = read.csv(files[5]) |> 
  tibble() |> 
  select(-X) |> 
  mutate(date = ymd_hms(date),
         site = "my1")
```

Binding.

-  Error on KC1.

-  Mutate no to be numeric (or just use the na argument of read.csv...)

```{r}
all_sites = bind_rows(cll2, hors, kc1, lon6, my1)
# errs on kc1
cll2

hors

kc1 # ahah!

# lets fix kc1s read

kc1 = read.csv(files[3]) |> 
  tibble() |> 
  select(-X) |> 
  mutate(date = ymd_hms(date),
         no = as.numeric(no),
         site = "kc1")

# hmmm, warnings are ok, but you can end up with side effects
# can we be better?

kc1 = read.csv(files[3]) |> 
  tibble() |> 
  select(-X) |> 
  mutate(date = ymd_hms(date),
         no = ifelse(no == "missing", NA, no) |> 
           as.numeric(),
         site = "kc1")

all_sites = bind_rows(cll2, hors, kc1, lon6, my1) #yay
```

Flow control - can we be lazier?

-  Explain loops.

-  What does a loop do?

-  What is the benefit of working this way? (compare to Excel - what happens if a new file appears? etc.)

```{r}
for (i in 1:length(files)) {
  # talk through what a loop is doing
  
  # two problems, how do we stop overwriting the previous data?
  dat = read.csv(files[i]) |>
    tibble() |>
    select(-X) |>
    mutate(
      date = ymd_hms(date),
      no = ifelse(no == "missing", NA, no) |>
        as.numeric(),
      site = "kc1"
    ) # how do we address the site issue?
}


# The storage issue -------------------------------------------------------

datList = list()
for (i in 1:length(files)) {
  # talk through what a loop is doing
  
  datList[[i]] = read.csv(files[i]) |>
    tibble() |>
    select(-X) |>
    mutate(
      date = ymd_hms(date),
      no = ifelse(no == "missing", NA, no) |>
        as.numeric(),
      site = "kc1"
    )
}

all_sites = bind_rows(datList)

# But really we only want to coerce the NA for the KCL site

datList = list()
for (i in 1:length(files)) {
  # talk through what a loop is doing
  
  # We know that KC1 is the third site, we will make this more explicit shortly
  if (i == 3) {
    datList[[i]] = read.csv(files[i]) |>
      tibble() |>
      select(-X) |>
      mutate(
        date = ymd_hms(date),
        no = ifelse(no == "missing", NA, no) |>
          as.numeric(),
        site = "kc1"
      )
  # LON6 is 4th site, need to parse as_datetime
  } else if (i == 4) {
    datList[[i]] = read.csv(files[i]) |>
      tibble() |>
      select(-X) |>
      mutate(
        date = as_datetime(date),
        site = "lon6"
      )
  } else {
    datList[[i]] = read.csv(files[i]) |>
      tibble() |>
      select(-X) |>
      mutate(
        date = ymd_hms(date),
        site = "kc1"
      )
  }
}
all_sites = bind_rows(datList)
# Ah but only have 2 sites, kc1 and lon6!
# Because in the 'else' we don't know what site we're on
all_sites |> count(site)
```

Fixing the sites.

-  Introduce `stringr` (tidyverse)

-  Add sites

```{r}
# The site problem --------------------------------------------------------

someText = "The quick brown fox jumped over the lazy dog"

word(someText, start = 2)

someMoreText = "The_quick_brown_underscore_separated_dog"

word(someMoreText)

word(someMoreText, sep = "_")

word(someMoreText, start = 3, sep = "_")

list.files("data/taught/part_2")

sites = list.files("data/taught/part_2") |>
  word(1, sep = "_")

# compact loop from earlier

datList = list()

for (i in 1:length(files)) {
  # Handle KC1 missing data
  if (sites[i] == 'KC1') {
    datList[[i]] = read.csv(files[i]) |>
      tibble() |>
      select(-X) |>
      mutate(
        date = ymd_hms(date),
        no = ifelse(no == "missing", NA, no) |>
          as.numeric(),
        site = sites[i]
      )
    # Handle LON6 different timestamp
  } else if (sites[i] == 'LON6') {
    datList[[i]] = read.csv(files[i]) |>
      tibble() |>
      select(-X) |>
      mutate(date = as_datetime(date),
             site = sites[i])
  } else {
    datList[[i]] = read.csv(files[i]) |>
      tibble() |>
      select(-X) |>
      mutate(date = ymd_hms(date),
             site = sites[i])
  }
}

all_sites = bind_rows(datList)
# Have all sites!
all_sites |> count(site)
```

### Exercise!

  - Reading in data exercise

## Manipulating, Reshaping and Summarising Data

Summaries.

-  Recall use of `mean`.

-  Can use with `summarise` - returns a data frame. 

-  Can give multiple arguments for multiple returns.

```{r}
mean(all_sites$nox, na.rm = T)

all_sites |> summarise(nox = mean(nox, na.rm = T))

all_sites |> summarise(mean_nox = mean(nox, na.rm = T),
                       sd_nox   = sd(nox, na.rm = T))
```

Grouping.

-  Use `group_by` - does next to nothing on its own.

-  Combine with `summarise` - see result.

-  Can arrange a dat with `dplyr`.

```{r}
all_sites |> 
  group_by(site)

all_sites |>
  group_by(site) |>
  summarise(mean_nox = mean(nox, na.rm = T),
            sd_nox   = sd(nox, na.rm = T))

all_sites |>
  group_by(site) |>
  summarise(mean_nox = mean(nox, na.rm = T),
            sd_nox   = sd(nox, na.rm = T)) |>
  arrange(mean_nox)
```

Reshaping.

-  A new, conceptually difficult bit of data handling.

-  Why is it important? Data structure.
  -  What is wide/untidy data?
  -  What is long/tidy data?
  -  Totally wide data would look like the below output - currently we're in a strange middle ground that is not useful.

```{r}
all_sites |>
  tidyr::pivot_wider(names_from = site, values_from = no:o3)
```

-  talk about e.g. what if you wanted to...
  -  calculate summaries for many columns?
  -  assign a flag if a pollutant was above a threshold?
  -  drop high o3 values but retain no/no2?
  -  drop other pollutants... but had a hundred of them?
  
-  Using `select`-style syntax to select columns.

```{r}
all_sites

all_sites |> pivot_longer(no:o3, names_to = "species", values_to = "conc")

all_sites |> pivot_longer(-c(site, date), names_to = "species", values_to = "conc") # another way of doing it

all_sites_long = all_sites |> pivot_longer(-c(site, date), names_to = "species", values_to = "conc")
```

Reshaped data - good for use for summaries.

```{r}
all_sites_long |>
  group_by(site, species) |>
  summarise(mean = mean(conc, na.rm = T),
            sd   =   sd(conc, na.rm = T))
```

- Show how much easier that is than writing out summary for every column in wide!
- And can then compare directly against each other

```{r}
all_sites_wide <- cll2 |> left_join(lon6, by='date', suffix=c("_cll2", "_lon6"))
mean(all_sites_wide$no_cll2, na.rm=T)
mean(all_sites_wide$no2_cll2, na.rm=T)
mean(all_sites$o3_cll2, na.rm=T)
mean(all_sites$no_lon6, na.rm=T)
mean(all_sites$no2_lon6, na.rm=T)
mean(all_sites$o3_lon6, na.rm=T)
sd(all_sites$no_cll2, na.rm=T)
sd(all_sites$no2_cll2, na.rm=T)
sd(all_sites$o3_cll2, na.rm=T)
sd(all_sites$no_lon6, na.rm=T)
sd(all_sites$no2_lon6, na.rm=T)
sd(all_sites$o3_lon6, na.rm=T)
```

Also works with mutate.

```{r}
all_sites_long |> 
  group_by(site, species) |> 
  mutate(p95 = quantile(conc, .95, na.rm = T),
         flag = conc > p95)
```

Reshaped data good for filtering.

- **NB: Difference between `=` and `==`

```{r}
all_sites_long |> 
  filter(site == "CLL2")

all_sites_long |> 
  filter(site %in% c("CLL2", "MY1", "somewhere_else"))
```

- Filtering much easier on tidy data too! Find all times when had NO > 10ppb

```{r}
# Easy in tidy
all_sites_long |>
  filter (species == 'no', conc > 10)

# In wide have to specify each column!
# Doesn't scale with number of sites!
all_sites_wide |>
  filter(no_cll2 > 10 | no_lon6 > 60 ...)

```

Grouped data also works with filter!

```{r}
all_sites_long |>
  group_by(site, species) |>
  filter(conc == max(conc, na.rm = T))
```

Can pivot wider again...

- One level of wide, tidy on site but wide on species

```{r}
all_sites_long |> 
  filter(site %in% c("CLL2", "LON6")) |> 
  pivot_wider(names_from = species, values_from = conc)
```

- Two levels of wide on both site and species

**NB: This is what we had when we did that `left_join` at the start**

```{r}
all_sites_long |> 
  filter(site %in% c("CLL2", "LON6")) |> 
  pivot_wider(names_from = c(site, species), values_from = conc)
```

### Exercise!

  - Data manipulation exercise

## Real World Exercise

Follow through with Real World Exercise section